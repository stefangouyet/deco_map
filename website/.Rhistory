library(tidyverse)
getwd()
df = read_csv('legislators-current.csv')
View(df)
View(df)
state_district_map = read_csv('Projects/USPS/usps_dailies/materials/state_district_map.csv')
View(state_district_map)
?left_join
df1 = df %>% left_join(state_district_map,by=c("state"="State_abb"))
View(df1)
df1 = df1 %>% select(full_name,type,state,party,gender)
df1 = df1 %>% select(full_name,type,state,party,gender,region)
df1 = df %>% left_join(state_district_map,by=c("state"="State_abb"))
df1 = df1 %>% select(full_name,type,state,party,gender,region)
df1 = df1 %>% select(full_name,type,state,party,gender,Region)
df1 = df %>% left_join(state_district_map,by=c("state"="State_abb"))
df1 = df1 %>% select(full_name,type,state,party,gender,Region,url)
df1 = df1 %>% mutate(url = url %>% str_remove('https://www.',''))
df1 = df1 %>% mutate(url = url %>% str_remove('https://www.'))
df1 = df1 %>% mutate(url = url %>% str_remove('https://www.'),
url = url %>% str_remove('https:/'),
url = url %>% str_remove('/public'))
df1 = df %>% left_join(state_district_map,by=c("state"="State_abb"))
df1 = df1 %>% select(full_name,type,state,party,gender,Region,url)
df1 = df1 %>% mutate(url = url %>% str_remove('https://www.'),
url = url %>% str_remove('https://'),
url = url %>% str_remove('/public'))
df1 = df %>% left_join(state_district_map,by=c("state"="State_abb"))
df1 = df1 %>% select(full_name,type,state,party,gender,Region,url)
df1 = df1 %>% mutate(url = url %>% str_remove('https://www.'),
url = url %>% str_remove('https://'),
url = url %>% str_remove('/public'),
url = url %>% str_remove('/'))
df1 = df1 %>% mutate(url = url %>% str_remove('https://www.'),
url = url %>% str_remove('https://'),
url = url %>% str_remove('/public'),
url = url %>% str_remove('/'),
url = url %>% str_remove('http:/'))
df1 = df %>% left_join(state_district_map,by=c("state"="State_abb"))
df1 = df1 %>% select(full_name,type,state,party,gender,Region,url)
df1 = df1 %>% mutate(url = url %>% str_remove('https://www.'),
url = url %>% str_remove('https://'),
url = url %>% str_remove('/public'),
url = url %>% str_remove('/'),
url = url %>% str_remove('http:/'))
df1 = df1 %>% mutate(title = paste("Office of ", if_else(type == "rep", "Representative", "Senator"), full_name))
df1 = df1 %>% mutate(title = paste("Office of ", if_else(type == "rep", "Representative", "Senator"), full_name, "(", party %>% substring(0,1)))
df1 = df1 %>% mutate(title = paste("Office of ", if_else(type == "rep", "Representative", "Senator"), full_name, "(", party %>% substring(0,1), "-", state))
df1 = df1 %>% mutate(title = paste("Office of ", if_else(type == "rep", "Representative", "Senator"), full_name, "(", party %>% substring(0,1), "-", state, ")"))
df1 = df1 %>% mutate(title = paste0("Office of ", if_else(type == "rep", "Representative", "Senator"), full_name, "(", party %>% substring(0,1), "-", state, ")"))
df1 = df1 %>% mutate(title = paste0("Office of ", if_else(type == "rep", "Representative ", "Senator "), full_name, "(", party %>% substring(0,1), "-", state, ")"))
df1 = df1 %>% mutate(title = paste0("Office of ", if_else(type == "rep", "Representative ", "Senator "), full_name, " (", party %>% substring(0,1), "-", state, ")"))
df1 %>% write_csv('senator_page_matchup.csv')
dirname()
dirname(sprintf("output-data/html/NationWideMap"))
normalizePath(dirname(sprintf("output-data/html/NationWideMap")))
normalizePath(dirname(sprintf("Zoom")))
normalizePath(dirname(sprintf("Zoom/")))
normalizePath(dirname(sprintf("Projects/Army")))
normalizePath(sprintf("Projects/Army"))
path_absolute = normalizePath(sprintf("output-data/html/NationWideMap_%s.html",strftime(now(), format='%Y%m%d')))
library(lubridate)
path_absolute = normalizePath(sprintf("output-data/html/NationWideMap_%s.html",strftime(now(), format='%Y%m%d')))
path_absolute = normalizePath(sprintf("Projects/Army/NationWideMap_%s.html",strftime(now(), format='%Y%m%d')))
shiny::runApp('test')
auth0::use_auth0()
install.packages('auth0')
auth0::use_auth0()
usethis::edit_r_environ()
auth0::shinyAppAuth0(ui, server)
shiny::runApp()
runApp()
runApp()
runApp('test')
runApp('test')
shiny::runApp('test')
shiny::runApp("app/directory/", port = 8100)
shiny::runApp("test/app.R", port = 8100)
shiny::runApp("test/", port = 8100)
shiny::runApp("test", port = 8100)
shiny::runApp("tests", port = 8100)
shiny::runApp("test/", port = 8100)
libary(tidyverse)
library(tidyverse)
andre_df <- read_csv('andre_df.csv')
andre_df <- read_csv('andre_df.csv')
andre_df <- read_csv('updated_dfs/andre_df.csv')
View(andre_df)
andre_df <- andre_df %>% head(20)
View(andre_df)
library(ggplot2)
andre_df %>% ggplot(aes(x = Date,
y = `1+ (cardio/gym)`)) +
geom_point()
andre_df %>%
mutate(x = replace_na(x, 0)) %>%
ggplot(aes(x = Date,
y = `1+ (cardio/gym)`)) +
geom_point()
andre_df %>%
replace_na(0)) %>%
andre_df %>%
replace_na(0) %>%
ggplot(aes(x = Date,
y = `1+ (cardio/gym)`)) +
geom_point()
andre_df %>%
mutate(`1+ (cardio/gym)` = replace_na(`1+ (cardio/gym)`, 0)) %>%
ggplot(aes(x = Date,
y = `1+ (cardio/gym)`)) +
geom_point()
andre_df %>%
mutate(`1+ (cardio/gym)` = replace_na(`1+ (cardio/gym)`, 0)) %>%
ggplot(aes(x = Date,
y = `1+ (cardio/gym)`)) +
geom_point() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
rm(list=ls())
library(tidyverse)
df <- read_csv('10_16_articles_database_concat.csv')
df <- read_csv('10_16_articles_database_concat.csv')
View(df)
df <- df %>% select(
area,content,audience,date,domain_plus,text,url, title, relevancy_score,site_name)
View(df)
df <- read_csv('10_16_articles_database_concat.csv')
View(df)
df <- df %>% select(
area,content,audience,date,domain_plus,text,url, title, relevancy_score,site_name,type)
df <- df %>% filter(type %in% c('matched', 'irrelevant')
df <- df %>% filter(type %in% c('matched', 'irrelevant'))
df <- df %>% filter(type %in% c('matched', 'irrelevant'))
View(df)
df %>% count(site_name,relevancy_score,sort=TRUE)
df %>% count(site_name,type,sort=TRUE)
df %>% count(site_name,domain_plus,sort=TRUE) %>%
df %>% count(site_name,domain_plus,sort=TRUE)
df %>% count(site_name,domain_plus,sort=TRUE)
df %>% count(domain_plus,type,sort=TRUE)
df <- read_csv('10_16_articles_database_concat.csv')
df <- read_csv('10_16_articles_database_concat.csv')
View(df)
df <- df %>% select(
area,content,audience,date,domain_plus,text,url, title, relevancy_score,site_name,type,source_title_draft)
df %>% count(domain_plus,type,sort=TRUE)
df %>% count(source_title_draft,type,sort=TRUE)
df <- df %>% filter(type %in% c('matched', 'irrelevant'))
df$type %>% unique()
df %>% count(source_title_draft,type,sort=TRUE) %>% group_by(source_title_draft) %>%
mutate(total_domain = sum(n),
within_domain = n/total_domain)
source_title_irrelevant <- df %>% count(source_title_draft,type,sort=TRUE) %>% group_by(source_title_draft) %>%
mutate(total_domain = sum(n),
within_domain = n/total_domain)
View(source_title_irrelevant)
df <- df %>% filter(type %in% c('matched', 'irrelevant'))
library(blogdown)
blogdown::install_hugo()
blogdown::new_site()
getwd()
getwd()
setwd('C:/Users/stefan.gouyet/Documents/Projects/deco_map/Website')
getwd()
blogdown::new_site()
blogdown::new_site(theme = 'gadenbuie/hyde')
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
